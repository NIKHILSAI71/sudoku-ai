# Training Configuration - Production Optimized
training:
  # Basic settings
  epochs: 60
  batch_size: 256  # Increased from 128 for better GPU utilization
  num_workers: 8   # Increased from 4 for faster data loading
  pin_memory: true
  prefetch_factor: 2          # NEW: Prefetch batches per worker
  persistent_workers: true    # NEW: Keep workers alive between epochs
  
  # Gradient Accumulation (NEW)
  gradient_accumulation_steps: 2  # Effective batch size: 256 * 2 = 512
  
  # Model EMA (NEW)
  ema:
    enabled: true
    decay: 0.9999  # Standard decay for production models
  
  # Early Stopping (NEW)
  early_stopping:
    enabled: true
    patience: 15       # Stop if no improvement for 15 epochs
    min_delta: 0.001   # Minimum improvement to count
    monitor: 'grid_accuracy'
  
  # Optimizer
  optimizer:
    type: "adamw"
    lr: 0.001
    weight_decay: 0.01
    betas: [0.9, 0.999]
  
  # Learning rate scheduler
  scheduler:
    type: "onecycle"  # Changed from reduce_on_plateau - better for finite training
    max_lr: 0.003     # 3x base learning rate
    pct_start: 0.3    # 30% of training for warmup
    anneal_strategy: "cos"
    # Alternative: cosine annealing (comment out onecycle, uncomment below)
    # type: "cosine"
    # T_max: 60
    # eta_min: 1.0e-6
  
  # Mixed precision training
  mixed_precision: true
  
  # Curriculum learning
  curriculum:
    enabled: true
    stage1_epochs: 15  # Easy puzzles (30-40 clues)
    stage2_epochs: 20  # Medium puzzles (22-35 clues)
    stage3_epochs: 25  # Hard puzzles (17-25 clues)
    
    difficulty_ranges:
      easy: [30, 40]    # Number of given clues
      medium: [22, 35]
      hard: [17, 25]
  
  # Data augmentation
  augmentation:
    digit_permutation: 0.2     # Randomly swap digit labels
    rotation: 0.25             # Random 90°/180°/270° rotation
    transpose: 0.15            # Transpose rows/columns
    row_col_permutation: 0.20  # Swap rows/cols within bands
  
  # Regularization
  dropout: 0.3
  label_smoothing: 0.05  # Increased from 0.0 for better generalization
  gradient_clip: 1.0
  
  # Enhanced Monitoring (NEW)
  monitoring:
    track_solve_rate: true      # % of fully solved puzzles
    track_confidence: true      # Mean prediction confidence
    track_entropy: true         # Prediction uncertainty
    track_constraints: true     # Sudoku rule violations
    adaptive_validation: true   # Validate less frequently as training progresses
  
  # Early stopping
  early_stopping:
    enabled: true
    patience: 10
    min_delta: 0.001
  
  # Checkpointing
  checkpoint:
    save_every: 5        # Save every N epochs
    save_best: true
    save_last: true
    monitor: "val_accuracy"
    mode: "max"
  
  # Validation
  val_split: 0.2
  val_every: 1  # Validate every N epochs
  
  # Loss function
  loss:
    type: "cross_entropy"
    constraint_penalty: 0.1  # Weight for constraint violation penalty
    
# Logging
logging:
  use_wandb: false
  project: "sudoku-ai"
  log_every: 100  # Log every N batches
  
  metrics:
    - cell_accuracy
    - grid_accuracy
    - constraint_violations
    - solve_rate

# Hardware
device: "cuda"  # cuda, cpu, mps
deterministic: false
seed: 42
