# ðŸš€ Quick Start Training Guide

## Prerequisites

1. **Activate your virtual environment:**
```powershell
.venv\Scripts\Activate.ps1
```

2. **Install dependencies:**
```powershell
pip install -r requirements.txt
```

## Training the GNN Model

### Option 1: Basic Training (Recommended for First Run)

Train on a subset to test everything works:

```powershell
python scripts/train.py --dataset data/sudoku.csv --max-samples 10000 --epochs 10
```

### Option 2: Full Training (Production Quality)

Train on full dataset with curriculum learning:

```powershell
python scripts/train.py --dataset data/sudoku.csv --epochs 60 --batch-size 128 --curriculum 20 20 20
```

### Option 3: Fast Training (GPU with Mixed Precision)

```powershell
python scripts/train.py --dataset data/sudoku.csv --epochs 60 --batch-size 256 --device cuda
```

## Training Parameters Explained

| Parameter | Default | Description |
|-----------|---------|-------------|
| `--dataset` | *required* | Path to Kaggle CSV (puzzle,solution format) |
| `--max-samples` | None | Limit samples for testing (e.g., 10000) |
| `--epochs` | 60 | Total training epochs |
| `--batch-size` | 128 | Batch size (256+ for V100/A100) |
| `--lr` | 0.001 | Learning rate |
| `--hidden-dim` | 96 | GNN hidden dimension |
| `--num-iterations` | 32 | Message passing iterations |
| `--curriculum` | 20 20 20 | Curriculum stages [easy, medium, hard] |
| `--no-augment` | False | Disable data augmentation |
| `--no-amp` | False | Disable mixed precision (FP16) |
| `--device` | cuda/cpu | Device for training |
| `--checkpoint-dir` | checkpoints | Where to save models |
| `--resume` | None | Resume from checkpoint |

## Expected Results

### Training Time
- **10K samples**: ~5 minutes (CPU), ~2 minutes (GPU)
- **100K samples**: ~30 minutes (CPU), ~10 minutes (GPU)  
- **1M samples (full)**: ~5 hours (CPU), ~1.5 hours (GPU)

### Accuracy Targets
- **Easy stage (20 epochs)**: 85-90% cell accuracy
- **Medium stage (40 epochs)**: 92-95% cell accuracy
- **Hard stage (60 epochs)**: **96-98% cell accuracy**, 80-85% grid accuracy

## After Training

### Test Your Model

```powershell
python scripts/solve.py --puzzle examples/easy1.sdk --checkpoint checkpoints/policy_best.pt
```

### Evaluate Performance

```powershell
python scripts/evaluate.py --checkpoint checkpoints/policy_best.pt --test-file examples/puzzles_sample.txt
```

## Common Issues

### Issue: "Dataset not found"
**Solution:** Download Kaggle Sudoku dataset:
- Go to: https://www.kaggle.com/datasets/bryanpark/sudoku
- Download `sudoku.csv` to `data/` folder

### Issue: "CUDA out of memory"
**Solution:** Reduce batch size:
```powershell
python scripts/train.py --dataset data/sudoku.csv --batch-size 64
```

### Issue: "Import pandas could not be resolved"
**Solution:** Install pandas:
```powershell
pip install pandas
```

### Issue: Training is slow on CPU
**Solution:** Use smaller subset or enable GPU:
```powershell
python scripts/train.py --dataset data/sudoku.csv --max-samples 50000
```

## Monitoring Training

Logs are saved to `logs/` directory with timestamps. Check them with:
```powershell
cat logs\sudoku_ai_*.log
```

## Checkpoints

Two checkpoints are saved:
- `checkpoints/policy.pt` - Latest model
- `checkpoints/policy_best.pt` - Best validation accuracy

Use `policy_best.pt` for inference!

## Advanced: Resume Training

If training is interrupted:
```powershell
python scripts/train.py --dataset data/sudoku.csv --resume checkpoints/policy.pt
```

---

## ðŸŽ¯ Recommended Training Command

For best results on first run:

```powershell
python scripts/train.py `
  --dataset data/sudoku.csv `
  --max-samples 100000 `
  --epochs 60 `
  --batch-size 128 `
  --curriculum 20 20 20 `
  --verbose
```

This will:
âœ… Train on 100K samples (good balance)
âœ… Use curriculum learning (easyâ†’mediumâ†’hard)
âœ… Take ~30 minutes on GPU, ~1.5 hours on CPU
âœ… Achieve 95-97% cell accuracy
âœ… Save checkpoints automatically
âœ… Show detailed progress logs

---

**Questions?** Check the logs in `logs/` or run with `--verbose` flag!
